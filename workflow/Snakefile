import pandas as pd


configfile: "config/config.yaml"


PREFIX = config["root_dir"]
ASSEMBLY = config.get("assembly", "GRCh38")
SAMPLES_TABLE = pd.read_csv(config["samples"])
samples = list(SAMPLES_TABLE["name"].values)
sample_bam_dict = {
    r.name: r.path for r in SAMPLES_TABLE.itertuples(index=False)
}

print(PREFIX)


rule final:
    input:
        expand(
            PREFIX
            + "/{assembly}/stringtie/S10/Exons_table_{cons_type}.tsv",
            assembly=[ASSEMBLY],
            cons_type=[config["conservation_file"]],
        ),


def get_missing_S6(wildcards):
    _, computed_samples = glob_wildcards(
        PREFIX + "/{assembly}/stringtie/S6/{sample_id}.tsv.gz"
    )
    missing_samples = list(set(samples) - set(computed_samples))
    return expand(
        PREFIX + "/{assembly}/stringtie/S6/{sample_id}.tsv.gz",
        sample_id=missing_samples,
        assembly=[ASSEMBLY],
    )


rule stringtie_all:
    input: expand(PREFIX + "/{assembly}/stringtie/S1/{sample_id}.gtf.gz", assembly=[ASSEMBLY], sample_id=samples)


localrules:
    merge_exon_list,
    merge_novel_exons,
    get_novel_bed,
    intersect_novel_bed,
    postprocess_novel_exons,
    aggregate_novel_exons,
    prepare_exons_and_genes_bed,
    parse_annotation
    # calculate_eCDF,
    #     aggregate_right_elements,


rule parse_annotation:
    input:
        gtf= "resources/annotation/{assembly}/{assembly}.annotation.gtf",
    output:
        pq="resources/annotation/{assembly}/Annotation_parsed.pq",
    conda:
        "./envs/polars.yaml"
    cache: True
    shell:
        """
mkdir -p $(dirname {output.pq})  
python -m workflow.scripts.parse_annotation_to_parquet \
    --input {input.gtf} \
    --output {output.pq} 
"""

if config["include_first_steps"]:
    rule stringtie:
        input:
            bam=lambda wildcards: sample_bam_dict[wildcards["sample_id"]],
            gtf="resources/annotation/{assembly}/{assembly}.annotation.gtf",
        output:
            gtf=PREFIX + "/{assembly}/stringtie/S1/{sample_id}.gtf.gz",
        threads: config["stringtie_threads"]
        conda:
            "./envs/stringtie.yaml"
        shell:
            """
    stringtie --conservative -G {input.gtf} -p {threads} {input.bam} | gzip > {output}
    """


    rule read_and_filter_exons:
        input:
            gtf=rules.stringtie.output.gtf,
            ipsa=PREFIX + "/{assembly}/pyIPSA/J6/{sample_id}.J6.gz",
            ann_gtf="resources/annotation/{assembly}/Annotation_parsed.pq",
        output:
            tsv=PREFIX + "/{assembly}/stringtie/S6/{sample_id}.tsv.gz",
        conda:
            "./envs/polars.yaml"
        resources:
            mem_mb=15000 
        shell:
            """
    mkdir -p $(dirname {output.tsv})  
    python -m workflow.scripts.filter_exons \
        --stringtie-gtf {input.gtf} \
        --annotation-gtf {input.ann_gtf} \
        --ipsa-junctions {input.ipsa} \
        --output {output.tsv} \
        --sample-name {wildcards.sample_id}
    """


rule merge_exon_list:
    input:
        tsv=lambda wildcards: expand(
            PREFIX + "/{assembly}/stringtie/S6/{sample_id}.tsv.gz",
            sample_id=samples,
            assembly=[wildcards.assembly],
        ),
    output:
        PREFIX + "/{assembly}/stringtie/S6.tmp.list",
    run:
        with open(output[0], "w") as out:
            out.write("\n".join(input))


rule merge_novel_exons:
    input:
        file_list=PREFIX + "/{assembly}/stringtie/S6.tmp.list",
    output:
        pq=PREFIX + "/{assembly}/stringtie/S6_merged.pq",
    conda:
        "./envs/polars.yaml"
    shell:
        """
python -m workflow.scripts.merge_exon_files \
    --input-list {input.file_list} \
    --output {output.pq} \
"""


rule aggregate_right_elements:
    input:
        pq=PREFIX + "/{assembly}/stringtie/S6_merged.pq",
        anno="resources/annotation/{assembly}/Annotation_parsed.pq",
    output:
        pq=PREFIX + "/{assembly}/stringtie/S7.pq",
    conda:
        "./envs/polars.yaml"
    resources:
        mem_mb=100000  
    log:
        PREFIX + "/{assembly}/stringtie/S7.log",
    shell:
        """
python -m workflow.scripts.aggregate_right_elements \
    --input {input.pq} \
    --annotation-pq {input.anno} \
    --output {output.pq} > {log}
"""


rule get_novel_bed:
    input:
        pq=PREFIX + "/{assembly}/stringtie/S7.pq",
    output:
        bed=PREFIX + "/{assembly}/stringtie/S7_novel.unsorted.bed",
    conda:
        "./envs/polars.yaml"
    params:
        radius=5,
    shell:
        """
python -m workflow.scripts.get_novel_bed \
    --radius {params.radius} \
    --input {input.pq} \
    --output {output.bed} 
"""


rule intersect_novel_bed:
    input:
        novel_bed=PREFIX + "/{assembly}/stringtie/S7_novel.unsorted.bed",
        cons_elements="resources/annotation/{assembly}/phastCons.{cons_type}.bed",
    output:
        bed=PREFIX + "/{assembly}/stringtie/S8/Annotated_{cons_type}.bed",
    conda:
        "./envs/default.yaml"
    shell:
        """
cat {input.novel_bed} |\
sort-bed - |\
bedmap --delim $'\t' --echo --wmean --bases-uniq-f - {input.cons_elements}\
> {output}
"""


rule calculate_eCDF:
    input:
        bed=PREFIX + "/{assembly}/stringtie/S8/Annotated_{cons_type}.bed",
        pq=PREFIX + "/{assembly}/stringtie/S7.pq",
    output:
        pq=PREFIX + "/{assembly}/stringtie/S9/Exons_w_eCDF_{cons_type}.pq",
    log:
        PREFIX + "/{assembly}/stringtie/S9/Exons_w_eCDF_{cons_type}.log",
    conda:
        "./envs/polars.yaml"
    params:
        max_as_length=150,
    resources:
        mem_mb=100000    
    shell:
        """
python -m workflow.scripts.calculate_eCDF \
    --input-pq {input.pq} \
    --input-bed {input.bed} \
    --max-as-length {params.max_as_length}\
    --output {output.pq} > {log}
"""

rule get_novel_bed_aux:
    input:
        pq=PREFIX + "/{assembly}/stringtie/S9/Exons_w_eCDF_{cons_type}.pq",
    output:
        bed=PREFIX + "/{assembly}/stringtie/S9/Exons_w_eCDF_{cons_type}.bed",
    conda:
        "./envs/polars.yaml"
    params:
        radius=5,
    shell:
        """
python -m workflow.scripts.get_novel_bed \
    --radius {params.radius} \
    --input {input.pq} \
    --output {output.bed} 
"""

rule intersect_novel_bed_aux:
    input:
        novel_bed=PREFIX + "/{assembly}/stringtie/S9/Exons_w_eCDF_{cons_type}.bed",
        annotated_exons_bed="resources/annotation/{assembly}/exons.bed",
    output:
        tsv=PREFIX + "/{assembly}/stringtie/S9/Annotated_{cons_type}.tsv",
    conda:
        "./envs/default.yaml"
    shell:
        """
cat {input.novel_bed} |\
sort-bed - |\
bedmap --delim $'\t' --echo --bases-uniq-f - {input.annotated_exons_bed} |\
cut -f4,6 > {output}
"""

rule postprocess_novel_exons:
    input:
        pq=PREFIX + "/{assembly}/stringtie/S9/Exons_w_eCDF_{cons_type}.pq",
        ann_is=PREFIX + "/{assembly}/stringtie/S9/Annotated_{cons_type}.tsv",
        meta_csv=config["samples"],
    output:
        tsv=PREFIX
        + "/{assembly}/stringtie/S10/Exons_table_{cons_type}.tsv",
    log:
        PREFIX
        + "/{assembly}/stringtie/S10/Exons_postprocess_{cons_type}.log",
    conda:
        "./envs/polars.yaml"
    shell:
        """
python -m workflow.scripts.postprocess_exons \
    --input-pq {input.pq} \
    --input-ann-is {input.ann_is} \
    --input-meta {input.meta_csv}\
    --output-table {output.tsv} > {log}
"""

rule all_novel_exons:
    input:
        tsv=lambda wildcards: expand(
            PREFIX + "/{assembly}/stringtie/S6/{sample_id}.tsv.gz",
            sample_id=samples,
            assembly=[ASSEMBLY],
        ),


rule missing_novel_exons:
    input:
        get_missing_S6,
